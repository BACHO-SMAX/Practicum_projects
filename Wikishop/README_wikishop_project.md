# Классификация токсичных комментариев для Викишоп (с использованием BERT)

## Описание проекта
Интернет-магазин «Викишоп» запускает новый функционал редактирования описаний товаров клиентами. 
Для обеспечения корректного взаимодействия пользователей требуется система автоматической модерации — 
инструмент, способный выявлять токсичные комментарии и отправлять их на ручную проверку.

Проект направлен на обучение модели классификации текста с целью распознавания токсичности комментариев.
Модель должна достигнуть значения метрики F1 не менее 0.75.

## Цель проекта
- Построить надёжную модель бинарной классификации комментариев: токсичный / не токсичный.
- Достичь F1-метрики ≥ 0.75 на тестовой выборке.
- Рассмотреть возможность применения модели BERT для повышения качества классификации.

## Данные
Файл `toxic_comments.csv` содержит два столбца:
- `text` — текст комментария,
- `toxic` — бинарный целевой признак (1 — токсичный, 0 — не токсичный).

## Структура репозитория
```
Practicum_projects/
│
├── wikishop-git.ipynb              # Основной ноутбук проекта
├── toxic_comments.csv              # Набор данных с разметкой
└── README.md                       # Этот файл
```

## Используемые библиотеки
- `pandas`, `numpy` — для обработки данных;
- `scikit-learn` — базовые модели, метрики;
- `torch`, `transformers` (HuggingFace) — для работы с BERT;
- `nltk`, `re`, `string` — для очистки и предобработки текста;
- `matplotlib`, `seaborn` — визуализация.

## Этапы проекта
1. **Предобработка данных**:
   - Очистка текста от лишних символов.
   - Токенизация и лемматизация.
   - Векторизация (TF-IDF / Word2Vec / BERT).

2. **Обучение моделей**:
   - Базовые модели: LogisticRegression, RandomForestClassifier, NaiveBayes.
   - Сравнение метрик на валидации (в т.ч. F1).
   - Использование предобученной модели BERT с трансформерами HuggingFace.
   - Тонкая настройка (fine-tuning) и обучение на GPU.

3. **Оценка качества**:
   - Анализ precision, recall, F1.
   - Проверка устойчивости модели на кросс-валидации.
   - Вывод итоговой F1-метрики ≥ 0.75.

## Выводы
- Модель BERT продемонстрировала наилучшие результаты на тестовой выборке, уверенно преодолев порог F1 = 0.75.
- При этом классические модели на TF-IDF также дали конкурентоспособные результаты при хорошей настройке гиперпараметров.
- Методология применима для автоматической фильтрации пользовательского контента в любых системах с открытыми комментариями.

## Результаты
Сервис классификации токсичных комментариев может быть внедрён в бизнес-процессы «Викишоп» и адаптирован к другим текстовым задачам модерации.
